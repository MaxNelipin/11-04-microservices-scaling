# 11-04-microservices-scaling

## Задача 1: Кластеризация

Предложите решение для обеспечения развертывания, запуска и управления приложениями.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- Поддержка контейнеров;
- Обеспечивать обнаружение сервисов и маршрутизацию запросов;  https://habr.com/ru/company/ruvds/blog/442646/
- Обеспечивать возможность горизонтального масштабирования;
- Обеспечивать возможность автоматического масштабирования;
- Обеспечивать явное разделение ресурсов доступных извне и внутри системы;
- Обеспечивать возможность конфигурировать приложения с помощью переменных среды, в том числе с возможностью безопасного хранения чувствительных данных таких как пароли, ключи доступа, ключи шифрования и т.п.  https://kubernetes.io/docs/concepts/configuration/secret/     https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/

Обоснуйте свой выбор.


Сервисы в Kubernetes предоставляют доступ к экземплярам вашего работающего в кластере микросервиса или приложения через сетевой порт. Найти адрес сервиса удобнее всего через обнаружение имен DNS.
Сервис Kubernetes использует специальные настройки внутренней сети кластера, прокси-компонент kube-proxy, и виртуальные IP-адреса, чтобы обеспечить прозрачный доступ к динамичному, имеющему склонность к постоянным обновления и перезапускам развертыванию Deployment.
Внутренняя реализация сервисов позволяет прозрачно работать с любым количеством экземпляров ваших микросервисов и включает в себя простые алгоритмы балансировки нагрузки. Для поиска экземпляров используются метки labels.
Кроме обычного адреса внутри кластера, вы также можете выбрать тип сервиса NodePort для собственного алгоритма балансировки нагрузки, или использовать встроенный балансировщик облачного кластера с помощью типа LoadBalancer.
Апробированной и рекомендованной практикой распределенных динамических систем является проверка готовности (readiness check) каждого работающего в кластере сервиса. Kubernetes предоставляет нам встроенную проверку готовности нескольких видов.

Модуль горизонтального автомасштабирования (HPA)

Как следует из названия, HPA масштабирует количество реплик pod'ов. В качестве триггеров для изменения количества реплик большинство девопсов используют нагрузку на процессор и память. Однако можно масштабировать систему на основе пользовательских метрик, их сочетания или даже внешних метрик.

Высокоуровневая схема работы HPA:

HPA непрерывно проверяет значения метрик, указанные при установке, с интервалом по умолчанию 30 секунд.
HPA пытается увеличить количество модулей, если достигнут заданный порог.
HPA обновляет количество реплик внутри контроллера развертывания/репликации.
Контроллер развертывания/репликации затем разворачивает все необходимые дополнительные модули.


HPA запускает процесс развертывания модулей при достижении порогового значения метрик

При использовании HPA учитывайте следующее:

Интервал проверки HPA по умолчанию составляет 30 секунд. Он устанавливается флагом horizontal-pod-autoscaler-sync-period в диспетчере контроллера.
Относительная погрешность по умолчанию составляет 10%.
После последнего увеличения количества модулей HPA ожидает стабилизации метрик в течение трех минут. Этот интервал устанавливается флагом horizontal-pod-autoscaler-upscale-delay.
После последнего уменьшения количества модулей HPA ожидает стабилизации в течение пяти минут. Этот интервал устанавливается флагом horizontal-pod-autoscaler-downscale-delay.
HPA лучше всего работает с объектами развертывания, а не с контроллерами репликации. Горизонтальное автомасштабирование несовместимо с последовательным обновлением (rolling update), которое напрямую манипулирует контроллерами репликации. При деплое количество реплик зависит непосредственно от объектов развертывания.

